[toc]

# 学习在亲和图上进行脸部聚类

* 论文名称：Learning to Cluster Faces on an Afﬁnity Graph
* 论文归属：IEEE计算机视觉和模式识别会议论文集（CVPR 2019）
* 参考资料：[项目](http://yanglei.me/project/ltc/)，[论文](https://arxiv.org/abs/1904.02749)，[代码](https://github.com/yl-1993/learn-to-cluster)
* 算法优点：对较大规模的数据集（如5M）也适用。
  
## 摘要

面部识别近年来取得了显着进步，其表现达到了很高的水平。将其提升到一个新的水平需要更大的数据，这将涉及过高的注释成本。因此，利用未标记的数据成为一种有吸引力的选择。最近的工作表明，聚集未标记的脸部是一种很有前景的方法，通常会带来显着的性能提升。然而，如何有效地聚类，特别是在大规模（即百万级或以上）数据集上，仍然是一个悬而未决的问题。一个关键的挑战在于群集模式的复杂变化，这使得传统的聚类方法难以满足所需的准确性。这项工作探索了一种新颖的方法，即学习集群而不是依靠手工制作的标准。特别，我们提出了一个基于图卷积网络的框架，它结合了检测和分割模块来精确定位面部聚类。实验表明，我们的方法可以产生更精确的脸部聚类，从而也可以在人脸识别中获得进一步的性能提升。

## 介绍

现代脸部识别系统的高精确性严重依赖于大规模注释性的训练数据的有效性。
我们可以轻易从网上获取大量的脸部图片，但标注是极度昂贵的。
探索未标注的数据，例如通过无监督或半监督学习的方法，已经成为引人注目的选择，吸引了学术界和工业界的兴趣。

探索未标注数据的一个自然的想法：将他们聚成“伪类”，使得它们可以被作为已标注的书，然后喂给监督学习管道。这种方法有良好的表现，但执行起来还是有很多值得去期待的。他们一般会使用无监督的方法，例如K-means、spectral clustering（谱聚类）、hierarchical clustering（层次聚类）和approximate rank-order，来聚集标注的脸部。这些方法依赖于简单的假设，例如：
* K-means隐含假设了每个簇的样本都围绕着单个中心。
* spectral clustering要求簇的规模要相对平衡。
  
因此，这些方法都无法处理复杂的簇结构，经常导致出现含有噪声的簇，特别是应用从真实世界中收集的大规模数据集。这个问题严重限制了算法性能的提升。

为了有效探索未标注的脸部数据，我们需要开发一个有效的聚类算法，来处理频繁在实际中出现的、具有复杂数据结构的数据。而依赖于简单的假设无法提供这种有效性。在此论文中，我们探索了一个不同的方法，来学习如何从数据中聚类。特别地，我们使用图卷积神经网络的强大表达能力来捕捉脸部集群的共同部分，以帮忙分离未标注的数据。

本文脸部聚类的框架：
* 依赖于基于图卷积神经网络而不是简单假设的结构化模式，我们的框架能够处理拥有复杂结构的簇。
* 传递途径类似于用于实例分割的Mask R-CNN，例如，生成候选框，识别正确的一个，通过掩膜（masks）改进它们。这些步骤分别由基于super-vertex的迭代候选框生成器、图卷积神经网络和图分割网络来实现。
* 与MaskR-CNN的对比：MaskR-CNN作用在二维图像网格（2D image grid），图卷积神经网络作用在任意结构的亲和图上。
  
![](images/Figure_1.png)
* 图1显示了现有的方法和我们的方法。蓝色的点和橙色的点分别代表两个类别。前面的依赖于特有的聚类机制的无监督学习方法可能无法处理拥有复杂内部结构的橙色的聚类。我们通过学习结构，来评估簇候选框（绿色方框）的不同结合以及输出高分支的簇。<font color=Green>根据图中的分值来确定具体的分类，例如比起分为0.88、0.82、0.83对应的三个类，（监督学习的作用下）分为0.88、0.91对应的两个类更加客观。</font> 
* 提高了在大规模脸部数据上聚类的精度，得到的F-score为85.66，优于无监督聚类的最佳结果和近期的近期发展水平。
* 若使用的数据是未标注的，则用在MegaFace上的脸部识别模型的表现从60.29提升到78.64，表现接近于在所有数据上使用监督学习（80.75）。
* 主要依赖于三个方面：
   * 首先以监督学习的方式实现自顶而下（top-down）的脸部聚类。<font color=Green>（如何理解top-down：由浅层特征到深层特征？）</font> 
   * the first work：将聚类作为基于图卷积神经网络的检测和分割（detection and segmentation pipeline）。
   * 我们的方法在大规模脸部聚类上得到很好的表现，使得脸部识别模型的表现靠近应用在已知簇上的监督学习的结果。


## 相关工作

**脸部聚类**
* 许多现有的脸部聚类的方法都是无监督的。
* 脸部聚类为探索大规模未标注数据提供了途径。
* 这个方面的研究还处于早期阶段，如何在大规模数据上进行脸部聚类的问题还在继续。
* 早期工作使用了手工制作的特征（hand-crafted features）和经典聚类算法，例如谱聚类（spectral clustering）。
* 近期工作使用了学习到的特征，例如，无监督形式的自上而下的聚类，自下而上的基于支持向量机的监督方法，使用由CNN脸部模型得到的深层特征并使用approximate rank-order metric来将图像对聚类成簇，使用基于线性支持向量机的相似度量方法来训练样本数据的最近邻，条件成对聚类（Conditional Pairwise Clustering）也即从条件随机域出发通过成对相似度来脸部聚类，通过minimal covering spheres of neighbourhoods来改善相似性度量以探索深层特征的局部结构，训练MLP分类器来聚合信息以发现更多的鲁棒关联从而由连通分支得到簇。
* 虽然是使用了深层特征，这些工作主要关注于设计新的相似度量，仍旧通过无监督方法来实现聚类。
* 本文的方法是学习如何以top-down的形式来聚类，基于检测与分割的范式，使得可以处理复杂结构的聚类问题。

**图卷积神经网络**
* 图卷积神经网络扩展了CNN以处理图形结构数据。
* 现有的工作展示了GCNs的优点，例如，强大的复杂图形模型建模能力。在以往的研究中，GCNs的使用带来了相当有效的性能提升，例如，使用GCNs来半监督分类，在链接预测（link prediction）中GCNs的表现优于其他方法，基于骨架的动作识别为人体关节建模。
* 本文使用GCN作为基本的机制来捕获亲和图上的集群模式，这是第一次使用GCN来学习如何以监督形式聚类。

## 方法论

* 监督学习形式的大规模脸部聚类，基于图卷积神经网络，在亲和图上的检测和分割问题的联合

给定脸部数据集，使用已训练的CNN对每张图片进行特征提取，形成一个特征集合(set of features)$D={f_i}_{i=1}^{N}$，其中$f_i$是$d$维向量。为了构建亲和图，我们将每个样本视为一个顶点，使用余弦相似度(cosine similarity)来找到每个样本的K个最近邻。<font color=Green>（注：K近邻算法中的K指的是测试对象的K个邻居；k-means算法中的k代表类簇个数，means代表类簇内数据对象的均值（这种均值是一种对类簇中心的描述），因此，k-means算法又称为k-均值算法。）</font> 为了连结邻居，我们由所有数据集得到亲和图$G=(V,\varepsilon)$。亲和图$G$可以用对称邻接矩阵$\textbf{A} \in \mathbb{R}^{N \times N}$，其中元素$a_{i,j}$表示，当两个顶点连接时$f_i$和$f_j$的余弦相似度，否则为0。亲和图是有着百万个点的大规模图。簇有如下性质：（1）不同的簇拥有不同标签的图片；（2）相同簇中的图片拥有相同的标签。


### 框架总览

![](images/Figure_2.png)

如图2，我们的聚类框架分为三个部分：
* 候选框生成（proposalgenerator）
* GCN-D
* GCN-S

GCN-D和GCN-S形成两阶段的程序，首先选择高质量的候选框，然后通过移除其中的噪声来提炼已选择的候选框。
GCN-D进行聚类检测，将聚类候选框作为输入，评估候选框如何构成理想中的簇。随后GCN-S通过分割来改进已选择的先验框。特别地，给定一个簇，它估计每个顶点成为噪声的可能性，然后通过丢弃分离物来剪枝。按照这两个GCNs，我们可以有效获得高质量的簇。

### 聚类候选框

比起直接处理大型的亲和图，我们先生成簇候选框。受到目标检测中生成区域先验框的方式的启发，这个策略基本上减少了计算成本，只有一定数量的簇的候选者需要被评估。一个簇的候选框$P_i$是亲和图$G$的子图。所有的先验框组成了集合$P=\{P_i\}^{N_p}_{i=1}$。簇候选框的生成是基于超顶点（super-vertices），所有的超定点形成集合$S={S_i}^{N_s}_{i=1}$。
* 生成超顶点，随后生成簇先验框。

**超顶点（Super-Vertex）** 
* 子图，含有少数点，这些点相互之间紧密联系。
* 表示：连通区域。
* 在亲和图$G$中相互连接的部分可以非常大。
* 为了保持每个超顶点内部的高连结性，移除亲和值小于阈值（threshold）$e_\tau$的边，控制超顶点的规模小于最大值$s_{max}$。
* 算法1展示了如何产生超顶点集合$S$。
* 一般的，拥有1M个定点的亲和图可以被分为50K个超顶点，平均每个包含20个顶点。

**候选框生成**
* 比起设想的簇，超顶点算是保守估计。尽管超顶点中的顶点可以尽最大可能描述同一个人，同一个人的多个样本也有可能被分配到多个超顶点中。
* 受到目标检测中的多尺度候选框的启发，我们设计了算法来生成多尺度的簇候选框。
* 正如算法2展示，我们在超定点之上构建了更高水平的图，超顶点的中心视为点，亲中心之间的亲和值视为边。在更高水平的图上，我们可以再次应用算法已来得到更大规模的候选框。通过迭代使用算法$I$次，则可以得到不同尺度的候选框。

![](images/Alg_12.png)

### 聚类检测

* 使用基于图卷积神经网络的GCN-D，从已生成的簇先验框中选择更高质量的簇。
* 衡量标准（两个矩阵）：$IoU$，$IoP$。
$$IoU(P)=\frac{|P \cap \widehat{P}|}{|P \cup \widehat{P}|}, IoP(P)=\frac{|P \cap \widehat{P}|}{|P|}, \tag{1}$$
其中$\widehat{P}$是包含含标签$l(P)$的所有定点的真值集合，$l(P)$是簇$P$的多数标签，例如，在$P$中出现次数最多的标签。
$IoU$反映了$P$与期望中的真值$\widehat{P}$的接近程度，$IoP$反映了纯度，例如，在$P$中有着标签$l(P)$的顶点的比例。

**GCN-D的设计** 假设高质量的簇在顶点中通常表现出确定的结构模式。我们用GCN来识别这样的簇。给定簇候选框$P_i$，GCN将与其顶点（记为$F_0(P_i)$）联系的视觉特征和亲和子矩阵$\textbf{A}(P_i)$作为输入，预测$IoU$和$IoP$。
在L层GCN网络中，每一层的计算公式如下：
$$\textbf{F}_{l+1}(P_i)=\sigma(\tilde{\textbf{D}}(P_i)^{-1}\textbf{A}(P_i)+\textbf{I})\textbf{F}_l(P_i)\textbf{W}_l), \tag{2}$$,
其中$\tilde{\textbf{D}}=\sum_{j}\tilde{\textbf{A}}_{ij}(P_i)$是对角度矩阵，$\textbf{F}_{l}(P_i)$包含第l层的嵌入，$\textbf{W}_l$是对嵌入进行变换的矩阵，$sigma$是非线性激活函数（本文中选择了$ReLU$）。这个公式表示对每个顶点和其邻居视为嵌入特征的加权平均，用$W_l$进行转换，然后喂给非线性激活函数。这个类似于CNN中的典型模块，期望它作用在含有任意拓扑结构的图上。在top-level的嵌入$\textbf{F}_{L}(P_i)$中，我们对$P_i$中的所有定点应用最大池化，得到可反映整体情况的特征向量。随后应用两个全连接层来分别预测$IoU$和$IoP$。

**训练和推断**

* 给定含有类标签的训练集，我们可以由公式(1)得到每个簇候选框$P(i)$在真值情况下的$IoU$和$ioP$。
* 随后训练GCN-D，目标在于将真值与预测值之间的均方误差MSE最小化。
* 经验表明，在没有花俏的技巧下，GCN可以提供准确的预测。
* 在推断阶段，我们使用训练好的$GCN-D$来预测每个候选框的$IoU$和$IoP$。$IoU$将会被用在**去重**中，来获得高$IoU$的候选框。$IoP$将会被用在下一阶段，来确定是否需要筛选候选框。

### 聚类分割

通过GCN-D识别得到的top候选框可能不够好，这些候选框可能含有一些需要被清除的分离物。我们使用GCN-S进行聚类分割，来清除候选框的分离物。

**GCN-S的设计**

GCN-S的结构类似于GCN-D，主要的区别在于预测的值。GCN-S给出的不是整个簇$P$的quality scores的预测值，而是每个顶点$v$是否为簇的成员的概率。
![](images/Figure 3.png)

**识别分离物**

* 为了训练GCN-S，我们需要准备真值，例如，用于识别分离物的真值。
* 一个自然的想法是，将所有标签与出现次数最多的标签不同的顶点视为分离物。如图3所示，对于不同标签含有相同数目顶点的候选框来说，这种方法可能会遇到困难。
* 为了避免对人工定义的分离物有过拟合的情况，我们希望模型学习不同的分割模式。只要分割结果含有某个类的顶点，无论是否是出现次数最多的标签，都将其视为合理的结果。特别地，我们随机选择了候选框的顶点作为种子。我们对每个顶点的特征定义了一个值，若为选择的种子则值为1否则为0。含有相同标签的种子顶点被视为正顶点，其他的顶点视为分离物。我们按照这种方案多次随机选择种子，因此从每个候选框$P$中得到多个训练样本。

**训练和推断**
在上述过程中，我们可以从保留的候选框中选择训练样本的集合。每个样本含有特征向量的集合，每个样本包含一组特征向量，每个特征向量用于顶点，亲和度矩阵，以及用于指示顶点是否为正的二元向量。
* 随后我们训练GCN-S，使用vertex-wise二值交叉熵作为损失函数。
* 在推断过程中，我们还可以为生成的簇候选框得出多个假设（threshold为0.5）。这个方法避免了与少数正counterparts联系的顶点被选为种子的情况。
* 我们只为GCN-S提供$IoP$值在0.3到0.7之间的候选框。因为当这候选框非常精准时，分离物通常是不需要删除的硬性示例。当候选框非常不精准时，有可能没有一个类占主导位置，因为该候选框不适合用GCN-S处理。按照GCN-S预测结果，我们从候选框中移除分离物。

### 去重

* 由上述三个阶段可以得到簇的结果。然而，有可能不同的簇之间出现重合，例如，共享某些顶点，这将给人脸识别的训练带来负面影响，因此有了去重的算法。
* 首先按照$IoU$值的大小对簇候选框进行降序排列，按照顺序连续收集候选框，通过移除前面的顶点来修正每个候选框。细节详见算法3。
* 比起目标检测的非极大值抑制（NMS），去重方法更加有效。前者的复杂度为$O(N^2)$，后者的复杂度为$O(N)$。
* 这个过程可以通过设置$IoU$的阈值来加快速度。
![](images/Alg_3.png)

## 拓展

**K-means**
* [kmeans聚类理论篇](https://www.cnblogs.com/bourneli/p/3645049.html)
* 无监督机器学习，缺点是需要先指定中心点的个数。

**Faiss**
* [Faiss流程与原理分析](https://www.cnblogs.com/yhzhou/p/10568728.html)

**Spectral Clustering**
* [谱聚类（Spectral Clustering）原理及Python实现](https://blog.csdn.net/songbinxu/article/details/80838865)

**hierarchical clustering**

**Bottom-Up and Top-Down**
* [强人工智能基本问题：自上而下，还是自下而上。](https://www.cnblogs.com/squirrel_sc/p/4521480.html)

**approximate rank-order**

**Graph Convolutional Networks (GCNs)**
* [图卷积神经网络整理](https://blog.csdn.net/weixin_39373480/article/details/90741121)
* [YouTube Video](https://www.youtube.com/watch?v=0_O8PdZBc5s&t=2097s)
* [Graph Convolutional Networks (GCNs) 简介](https://www.cnblogs.com/wangxiaocvpr/p/8059769.html)

**k近邻算法（knn）**
* [机器学习：K-近邻算法（KNN）](https://www.cnblogs.com/fwl8888/p/9661130.html)